{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fd0022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Grace\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow=\n",
    "#!pip install tflearn\n",
    "\n",
    "import nltk \n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "import random\n",
    "import numpy as np \n",
    "import json\n",
    "import tflearn\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from colorama import Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32cde84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 14499  | total loss: \u001b[1m\u001b[32m0.00037\u001b[0m\u001b[0m | time: 0.069s\n",
      "| Adam | epoch: 500 | loss: 0.00037 - acc: 1.0000 -- iter: 224/230\n",
      "Training Step: 14500  | total loss: \u001b[1m\u001b[32m0.00035\u001b[0m\u001b[0m | time: 0.074s\n",
      "| Adam | epoch: 500 | loss: 0.00035 - acc: 1.0000 -- iter: 230/230\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\Grace\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Grace\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "#ChatBot!!!\n",
    "#it takes a couple of minutes to train\n",
    "\n",
    "with open(\"graceintents.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "try:\n",
    "    with open(\"data.pickle\",\"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    words = []\n",
    "    labels = []\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "    for intent in data[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            docs_y.append(intent[\"tag\"])\n",
    "            \n",
    "        if intent[\"tag\"] not in labels:\n",
    "            labels.append(intent[\"tag\"])\n",
    "\n",
    "\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "    words = sorted(list(set(words)))\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "               bag.append(1)\n",
    "            else:\n",
    "              bag.append(0)\n",
    "    \n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "        \n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "    training = np.array(training)\n",
    "    output = np.array(output)\n",
    "    \n",
    "    with open(\"data.pickle\",\"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "model.fit(training, output, n_epoch= 500, batch_size=8, show_metric=True)\n",
    "model.save(\"model.tflearn\")\n",
    "\n",
    "try:\n",
    "    model.load(\"model.tflearn\")\n",
    "except:\n",
    "    model.fit(training, output, n_epoch= 500, batch_size=8, show_metric=True)\n",
    "    model.save(\"model.tflearn\")\n",
    "\n",
    "\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "    \n",
    "    return np.array(bag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e66bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with the bot! (type quit to stop) \n",
      "\n",
      "\u001b[43mAsk the bot about the movies:\n",
      "\u001b[0m\n",
      " David Attenborough: A Life on Our Planet \n",
      " Inception \n",
      " Forrest Gump \n",
      " Anbe Sivam \n",
      " Bo Burnham: Inside \n",
      " Saving Private Ryan \n",
      " Django Unchained \n",
      " Dangal \n",
      " Bo Burnham: Make Happy \n",
      " Louis C.K.: Hilarious \n",
      " Dave Chappelle: Sticks & Stones \n",
      " 3 Idiots \n",
      " Black Friday \n",
      " Super Deluxe\n",
      " \n",
      "\n",
      "\u001b[43mYou can ask about the actors, directors, runtime, release date, or rating.\n",
      "\u001b[0m \n",
      " \n",
      " \n",
      "\n",
      "You: Hi\n",
      "hurry up, I don't have all day\n",
      "You: What is three idiots rated\n",
      "This is the rating :  8.4 out of 10, according to IMDB voters \n",
      "You: Who acts in Black Friday\n",
      "This is the list:  Kay Kay Menon\n",
      "Pavan Malhotra\n",
      "Aditya Srivastava\n",
      "Dibyendu Bhattacharya\n",
      "Kishore Kadam\n",
      "Gajraj Rao\n",
      "Zakir Hussain\n",
      "Imtiaz Ali\n",
      "Pankaj Jha\n",
      "Pratima Kazmi\n",
      "Nawazuddin Siddiqui\n",
      "Vijay Maurya\n",
      "Ragesh Asthana\n",
      "Raj Singh Chaudhary\n",
      "Ashraf Ul Haq\n",
      "Murali Sharma\n",
      "Anil Yadav\n",
      "Sujata Sehgal\n",
      "Pranay Narayan\n",
      "Prakash Jais\n",
      "Goutam Maitra\n",
      "Sharad Ponkshe\n",
      "Aliya Curmally\n",
      "Savi Sidhu\n",
      "Asif Basra\n",
      "Anurag Kashyap\n",
      "\n",
      "You: Who directs inception\n",
      "Here you go : Christopher Nolan\n",
      "\n",
      "You: when was dangal released\n",
      "This is the year :  2016\n",
      "You: how long is bo burnham inside\n",
      "This is the runtime : 87 minutes\n",
      "You: who acts in bo burnham inside\n",
      "Here you go : Bo Burnham\n",
      "\n",
      "You: who directs bo burnham inside\n",
      "This is the director : Bo Burnham\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can ask the bot 5 different types of questions about 13 different movies\n",
    "\n",
    "\n",
    "def chat():\n",
    "    \n",
    "    movies =  \"\\n David Attenborough: A Life on Our Planet \\n Inception \\n Forrest Gump \\n Anbe Sivam \\n Bo Burnham: Inside \\n Saving Private Ryan \\n Django Unchained \\n Dangal \\n Bo Burnham: Make Happy \\n Louis C.K.: Hilarious \\n Dave Chappelle: Sticks & Stones \\n 3 Idiots \\n Black Friday \\n Super Deluxe\"\n",
    "    print(\"Start talking with the bot! (type quit to stop) \\n\")\n",
    "    print(Back.YELLOW + \"Ask the bot about the movies:\" )\n",
    "          \n",
    "    print(Style.RESET_ALL + movies + \"\\n \\n\")\n",
    "    \n",
    "    print(Back.YELLOW + \"You can ask about the actors, directors, runtime, release date, or rating.\"  )\n",
    "    print(Style.RESET_ALL + \" \\n \\n \\n\")\n",
    "    while True:\n",
    "        inp = input(\"You: \")\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "\n",
    "        result = model.predict([bag_of_words(inp, words)])[0]\n",
    "        result_index = np.argmax(result)\n",
    "        tag = labels[result_index]\n",
    "\n",
    "        if result[result_index] > 0.7:\n",
    "            for tg in data[\"intents\"]:\n",
    "                if tg['tag'] == tag:\n",
    "                    responses = tg['responses']\n",
    "            print(random.choice(responses))\n",
    "\n",
    "        else:\n",
    "            print(\"I didnt get that. Can you explain or try again.\")\n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd282450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a9a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81e04ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
